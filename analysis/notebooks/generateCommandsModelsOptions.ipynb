{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d9412c-ebe7-4d46-ad46-54b2e8b58f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17493092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCodeFromBinary(s):\n",
    "    for i in range(len(s)):\n",
    "        if s[i].isalpha():\n",
    "            return getCodeFromBinary(s[:i] + '0' + s[i+1:]) + getCodeFromBinary(s[:i] + '1' + s[i+1:])\n",
    "    return [int(s, 2)]\n",
    "\n",
    "def getVarNames(listVars):\n",
    "    return \"_\".join([\"v\" + str(v) for v in listVars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0626bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateModelsDict(startIndex=0, numModels=10, nameOptionsFile = \"/home/submit/pdmonte/CMSSW_10_6_27/src/Hrare2023/analysis/TMVA_regression/optionModels.out\", centralValues=None):\n",
    "    '''This function has to solve the following:\n",
    "        - Create a model and append it to a dictionary\n",
    "        - Save in a file the id of the model and the properties'''\n",
    "    \n",
    "    allModels = {}\n",
    "    with open(nameOptionsFile, \"a\") as file:\n",
    "        for i in range(numModels):\n",
    "            modelOptions = getRandomOptions(centralValues=centralValues)\n",
    "            allModels[startIndex + i] = getOptionsString(modelOptions)\n",
    "            file.write(str(startIndex + i) + ' $ ' + ' $ '.join(modelOptions.values()) + \"\\n\")\n",
    "\n",
    "    return allModels\n",
    "    \n",
    "\n",
    "def getOptionsString(modelDict):\n",
    "    outString = \"\\\"!V\"\n",
    "    if modelDict[\"VarTransform\"] != \"\":\n",
    "        outString += \":VarTransform=\" + modelDict[\"VarTransform\"]\n",
    "    outString += \":NTrees=\" + modelDict[\"NTrees\"]\n",
    "    outString += \":BoostType=\" + modelDict[\"BoostType\"]\n",
    "    outString += \":Shrinkage=\" + modelDict[\"Shrinkage\"]\n",
    "    outString += \":MaxDepth=\" + modelDict[\"MaxDepth\"]\n",
    "    outString += \":SeparationType=\" + modelDict[\"SeparationType\"]\n",
    "    outString += \":nCuts=\" + modelDict[\"nCuts\"]\n",
    "    outString += \":UseRandomisedTrees=\" + modelDict[\"UseRandomisedTrees\"]\n",
    "    outString += \":UseNvars=\" + modelDict[\"UseNvars\"]\n",
    "    outString += \":UseBaggedBoost=\" + modelDict[\"UseBaggedBoost\"]\n",
    "    outString += \":BaggedSampleFraction=\" + modelDict[\"BaggedSampleFraction\"]\n",
    "    outString += \":PruneMethod=\" + modelDict[\"PruneMethod\"]\n",
    "    outString += \":PruneStrength=\" + modelDict[\"PruneStrength\"]\n",
    "    outString += \":PruningValFraction=\" + modelDict[\"PruningValFraction\"]\n",
    "    outString += \"\\\"\"\n",
    "    return outString\n",
    "\n",
    "\n",
    "def getRandomOptions(centralValues=None):\n",
    "    outOptions = {}\n",
    "    if centralValues is None or len(centralValues) != 12:\n",
    "        outOptions[\"VarTransform\"] = getVarTransformChoice(maxSymbols=4)\n",
    "        outOptions[\"NTrees\"] = str(getRandomInt(1500, 5000))\n",
    "        outOptions[\"BoostType\"] = \"Grad\"\n",
    "        outOptions[\"Shrinkage\"] = str(getRandomFloat(0.10, 0.5))\n",
    "        outOptions[\"MaxDepth\"] = str(getRandomInt(5, 10))\n",
    "        outOptions[\"SeparationType\"] = \"RegressionVariance\"\n",
    "        outOptions[\"nCuts\"] = str(getRandomInt(15, 100))\n",
    "        outOptions[\"UseRandomisedTrees\"] = getRandomBool()\n",
    "        outOptions[\"UseNvars\"] = str(getRandomInt(2, 100))\n",
    "        outOptions[\"UseBaggedBoost\"] = getRandomBool()\n",
    "        outOptions[\"BaggedSampleFraction\"] = str(getRandomFloat(0.50, 5.00))\n",
    "        outOptions[\"PruneMethod\"] = getPruneMethodChoice()\n",
    "        outOptions[\"PruneStrength\"] = str(getRandomInt(0, 100))\n",
    "        outOptions[\"PruningValFraction\"] = str(getRandomFloat(0.0, 2.0))\n",
    "    else:\n",
    "        outOptions[\"VarTransform\"] = getVarTransformChoice(maxSymbols=4, meanSigma=centralValues[0])\n",
    "        outOptions[\"NTrees\"] = str(getRandomInt(1000, 5000, meanSigma=centralValues[1], spacing=100))\n",
    "        outOptions[\"BoostType\"] = \"Grad\"\n",
    "        outOptions[\"Shrinkage\"] = str(getRandomFloat(0.04, 0.5, meanSigma=centralValues[2]))\n",
    "        outOptions[\"MaxDepth\"] = str(getRandomInt(4, 10, meanSigma=centralValues[3]))\n",
    "        outOptions[\"SeparationType\"] = \"RegressionVariance\"\n",
    "        outOptions[\"nCuts\"] = str(getRandomInt(10, 100, meanSigma=centralValues[4]))\n",
    "        outOptions[\"UseRandomisedTrees\"] = getRandomBool(meanSigma=centralValues[5])\n",
    "        outOptions[\"UseNvars\"] = str(getRandomInt(5, 100, meanSigma=centralValues[6]))\n",
    "        outOptions[\"UseBaggedBoost\"] = getRandomBool(meanSigma=centralValues[7])\n",
    "        outOptions[\"BaggedSampleFraction\"] = str(getRandomFloat(0.70, 5.00, meanSigma=centralValues[8]))\n",
    "        outOptions[\"PruneMethod\"] = getPruneMethodChoice(meanSigma=centralValues[9])\n",
    "        outOptions[\"PruneStrength\"] = str(getRandomInt(0, 100, meanSigma=centralValues[10]))\n",
    "        outOptions[\"PruningValFraction\"] = str(getRandomFloat(0.0, 2.0, meanSigma=centralValues[11]))\n",
    "    return outOptions\n",
    "\n",
    "\n",
    "def getVarTransformChoice(minSymbols=0, maxSymbols=2, meanSigma=None):\n",
    "    # todo with sigma\n",
    "    nTsf = np.random.randint(minSymbols, maxSymbols+1)\n",
    "    varTransform = [\"P\", \"G\", \"D\", \"N\"]\n",
    "    good = []\n",
    "    initList = list(product(varTransform, repeat=nTsf))\n",
    "    for e in initList:\n",
    "        repeated = False\n",
    "        for i in range(len(e)-1):\n",
    "            if e[i] == e[i+1]:\n",
    "                repeated = True\n",
    "        if e.count(\"P\") > 1:\n",
    "            repeated = True\n",
    "        if not repeated:\n",
    "            good.append(\",\".join(e))\n",
    "    if meanSigma is None:\n",
    "        return np.random.choice(good)\n",
    "    else:\n",
    "        if np.random.uniform(0, 1) < meanSigma[1]:\n",
    "            return meanSigma[0]\n",
    "        else:\n",
    "            return np.random.choice(good)\n",
    "\n",
    "\n",
    "def getBestVarTransform(n=30):\n",
    "    best = [\"G\", \"N,G,N,G\", \"\", \"N\", \"P,N,D\", \"P,N,D,N\", \"P,G\", \"P,N\", \"P,D\", \"P\", \"N,G\", \"G,N\", \"G,N,G,N\", \"N,G,N\", \"G,N,G\", \"P,D,N\", \"P,D,N,D\", \"N,P,D\", \"N,P,N,D\", \"N,P,G\", \"P,D,G\", \"D,N,D\", \"P,G,N\", \"P,N,G\", \"D,N,G\", \"P,G,N,G\", \"D\", \"P,N,P,D\"]\n",
    "    return best[:n]\n",
    "\n",
    "\n",
    "def getPruneMethodChoice(meanSigma=None):\n",
    "    return getRandomItem([\"NoPruning\", \"NoPruning\", \"ExpectedError\", \"CostComplexity\"], meanSigma=meanSigma)\n",
    "\n",
    "\n",
    "def getRandomInt(minNum = 0, maxNum=100, meanSigma=None, spacing=1):\n",
    "    if meanSigma is None:\n",
    "        return int(np.round(np.random.randint(minNum, maxNum+1)/spacing, 0)*spacing)\n",
    "    else:\n",
    "        num = np.random.normal(meanSigma[0], meanSigma[1])\n",
    "        while num < minNum or num > maxNum:\n",
    "            num = np.random.normal(meanSigma[0], meanSigma[1])\n",
    "        return int(np.round(num/spacing, 0)*spacing)\n",
    "\n",
    "\n",
    "def getRandomFloat(minNum = 0.0, maxNum=1.0, meanSigma=None):\n",
    "    if meanSigma is None:\n",
    "        return np.round(np.random.uniform(minNum, maxNum), 3)\n",
    "    else:\n",
    "        num = np.random.normal(meanSigma[0], meanSigma[1])\n",
    "        while num < minNum or num > maxNum:\n",
    "            num = np.random.normal(meanSigma[0], meanSigma[1])\n",
    "        return np.round(num, 3)\n",
    "    \n",
    "\n",
    "def getRandomBool(meanSigma=None):\n",
    "    return getRandomItem([\"F\", \"T\"], meanSigma=meanSigma)\n",
    "\n",
    "        \n",
    "def getRandomItem(listOfChoices, meanSigma=None):\n",
    "    if meanSigma is None:\n",
    "        return np.random.choice(listOfChoices)\n",
    "    else:\n",
    "        remainingChoices = [x for x in listOfChoices if x != meanSigma[0]]\n",
    "        if np.random.uniform(0, 1) < meanSigma[1]:\n",
    "            return meanSigma[0]\n",
    "        else:\n",
    "            return np.random.choice(remainingChoices)\n",
    "\n",
    "def getInitValsModelOptions(modelsId, variances= [0.5, 600, 0.15, 2, 10, 0.7, 10, 0.7, 0.2, 0.6, 10, 0.3], fileName=\"/home/submit/pdmonte/CMSSW_10_6_27/src/Hrare2023/analysis/TMVA_regression/optionModels.out\"):\n",
    "    column_names = ['Id', 'VarTsf', 'NTrees', 'BoostType', 'Shrinkage', 'MaxDepth', 'SeparationType', 'nCuts', 'RndmTrees',\n",
    "                    'UseNvars', 'UseBaggedBoost', 'BaggedSampleFraction', 'PruneMethod', 'PruneStrength', 'PruningValFraction']\n",
    "    column_data_types = {'Id': int, 'VarTsf': str, 'NTrees': int, 'BoostType': str, 'Shrinkage': float, 'MaxDepth': int, 'SeparationType': str, 'nCuts': int, 'RndmTrees': str,\n",
    "                    'UseNvars': int, 'UseBaggedBoost': str, 'BaggedSampleFraction': float, 'PruneMethod': str, 'PruneStrength': int, 'PruningValFraction': float}\n",
    "    \n",
    "    df = pd.read_csv(fileName, sep='$', names=column_names, dtype=column_data_types)\n",
    "    df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    df = df[df[\"Id\"].isin(modelsId)]\n",
    "    selected_columns = ['VarTsf', 'NTrees', 'Shrinkage', 'MaxDepth', 'nCuts', 'RndmTrees', 'UseNvars', 'UseBaggedBoost', \n",
    "                        'BaggedSampleFraction', 'PruneMethod', 'PruneStrength', 'PruningValFraction']\n",
    "    list_of_lists = df[selected_columns].values.tolist()\n",
    "    list_of_lists = [[[op, vr] for op, vr in zip(model, variances)] for model in list_of_lists]\n",
    "\n",
    "    return list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afd6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad8c35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o40600_v01_ggh:::root -l -q -b 'TMVA_GF_regression.C(\"BDTG_df15_dl3684_v0_v1_opt40600\", \"d0starrho\", \"ggh\", 0, {0, 1}, 15, 3684, \"!V:NTrees=1300:BoostType=Grad:Shrinkage=0.141:MaxDepth=5:SeparationType=RegressionVariance:nCuts=67:UseRandomisedTrees=T:UseNvars=49:UseBaggedBoost=T:BaggedSampleFraction=1.223:PruneMethod=CostComplexity:PruneStrength=4:PruningValFraction=1.67\")' && root -l -q -b 'TMVA_GF_regression.C(\"BDTG_df15_dl3684_v0_v1_opt40600\", \"d0starrho\", \"ggh\", 1, {0, 1}, 15, 3684, \"!V:NTrees=1300:BoostType=Grad:Shrinkage=0.141:MaxDepth=5:SeparationType=RegressionVariance:nCuts=67:UseRandomisedTrees=T:UseNvars=49:UseBaggedBoost=T:BaggedSampleFraction=1.223:PruneMethod=CostComplexity:PruneStrength=4:PruningValFraction=1.67\")' && root -l -q -b 'TMVA_GF_regression.C(\"BDTG_df15_dl3684_v0_v1_opt40600\", \"d0starrho\", \"ggh\", 2, {0, 1}, 15, 3684, \"!V:NTrees=1300:BoostType=Grad:Shrinkage=0.141:MaxDepth=5:SeparationType=RegressionVariance:nCuts=67:UseRandomisedTrees=T:UseNvars=49:UseBaggedBoost=T:BaggedSampleFraction=1.223:PruneMethod=CostComplexity:PruneStrength=4:PruningValFraction=1.67\")' && python computeErrors.py -m BDTG_df15_dl3684_v0_v1_opt40600 -c d0starrho -p ggh\n"
     ]
    }
   ],
   "source": [
    "channel=\"d0starrho\"\n",
    "cat = \"ggh\"\n",
    "f = open(\"commands_temp.txt\", \"a\")\n",
    "comm = \"RECO:::python computeErrors.py -m RECO -c {channel}\".format(channel=channel)\n",
    "#print(comm)\n",
    "f.write(comm + \"\\n\")\n",
    "dfC, dlC = 7, 3684\n",
    "\n",
    "modelNames=[\"BDTG_df15_dl3684_v0_v1\"] #13/3620 Drho\n",
    "#modelNames=[\"BDTG_df13_dl3620_v0_v1\"] #13/3620 omega/phi\n",
    "#modelNames=[\"BDTG_df7_dl3684_v0_v1\"] #5/3620 D\n",
    "\n",
    "goodModels = [30000]\n",
    "goodModels = [30001] #omega\n",
    "goodModels = [30002] #d0star\n",
    "goodModels = [30003] #d0starrho\n",
    "#goodModels = [30000, 30001, 30002, 30003]\n",
    "\n",
    "#optionsDict = {0: \"\\\"!V:NTrees=1000:BoostType=Grad:Shrinkage=0.2:MaxDepth=5:SeparationType=SDivSqrtSPlusB:nCuts=90:UseRandomisedTrees=T:UseNvars=67:UseBaggedBoost:BaggedSampleFraction=2.4:PruneMethod=NoPruning\\\"\"}\n",
    "\n",
    "#initVals = [[\"G\", 0.3], [2000, 200], [0.2, 0.001], [7, 1], [30, 1], [\"F\", 0.37], [30, 1], [\"F\", 0.15], [1.0, 1], [\"NoPruning\", 0.677], [50, 1], [1, 1]]\n",
    "\n",
    "#initVals = getInitValsModelOptions(goodModels, variances = [0.5, 700, 0.07, 1.5, 10, 0.6, 8, 0.6, 0.25, 0.6, 8, 0.25], fileName=\"/home/submit/pdmonte/CMSSW_10_6_27/src/Hrare2023/analysis/TMVA_regression/optionModels.out\")\n",
    "#initVals = getInitValsModelOptions(goodModels, variances = [0.6, 250, 0.04, 1.1, 8, 0.6, 7, 0.6, 0.20, 0.6, 7, 0.20], fileName=\"/home/submit/pdmonte/CMSSW_10_6_27/src/Hrare2023/analysis/TMVA_regression/optionModels.out\")\n",
    "initVals = getInitValsModelOptions(goodModels, variances = [0.9999999, 0.000001, 0.000001, 0.000001, 0.000001, 0.9999999, 0.000001, 0.9999999, 0.000001, 0.9999999, 0.000001, 0.000001], fileName=\"/home/submit/pdmonte/CMSSW_10_6_27/src/Hrare2023/analysis/TMVA_regression/optionModels.out\")\n",
    "\n",
    "for k, init in enumerate(initVals):\n",
    "    numMod = 1\n",
    "    optionsDict = generateModelsDict(startIndex=40600+k*numMod, numModels=numMod, nameOptionsFile = \"/home/submit/pdmonte/CMSSW_10_6_27/src/Hrare2023/analysis/TMVA_regression/optionModels.out\", centralValues=init)\n",
    "    #optionsDict = generateModelsDict(startIndex=2103, numModels=1200)\n",
    "\n",
    "    for key, v in optionsDict.items():\n",
    "        for line in modelNames:\n",
    "            jobName = line.strip()\n",
    "            dfC = jobName.split(\"_\")[1].replace(\"df\", \"\")\n",
    "            dlC = jobName.split(\"_\")[2].replace(\"dl\", \"\")\n",
    "            listVars = [int(x.replace(\"v\", \"\")) for x in jobName.split(\"_\")[3:]]\n",
    "            varNamesShort = \"\".join([str(v) for v in listVars])\n",
    "            comm = \"o{idx}_v{varNamesShort}_{prodCat}:::root -l -q -b 'TMVA_GF_regression.C(\\\"BDTG_df{dfC}_dl{dlC}_{varNames}_opt{idx}\\\", \\\"{channel}\\\", \\\"{prodCat}\\\", 0, {{{listVars}}}, {dfC}, {dlC}, {optStr})' && root -l -q -b 'TMVA_GF_regression.C(\\\"BDTG_df{dfC}_dl{dlC}_{varNames}_opt{idx}\\\", \\\"{channel}\\\", \\\"{prodCat}\\\", 1, {{{listVars}}}, {dfC}, {dlC}, {optStr})' && root -l -q -b 'TMVA_GF_regression.C(\\\"BDTG_df{dfC}_dl{dlC}_{varNames}_opt{idx}\\\", \\\"{channel}\\\", \\\"{prodCat}\\\", 2, {{{listVars}}}, {dfC}, {dlC}, {optStr})' && python computeErrors.py -m BDTG_df{dfC}_dl{dlC}_{varNames}_opt{idx} -c {channel} -p {prodCat}\".format(dfC=dfC, dlC=dlC, channel=channel, prodCat=cat, listVars=str(listVars)[1:-1], varNames=getVarNames(listVars), varNamesShort=varNamesShort, idx=key, optStr=v)\n",
    "            print(comm)\n",
    "            f.write(comm + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5a749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e96ddbde",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the remaining models to compute\n",
    "completed = []\n",
    "file_path = \"completedModels.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        completed.append(line.strip())\n",
    "print(len(completed), completed[0])\n",
    "\n",
    "total = []\n",
    "file_path = \"totalModels.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        total.append(line.strip())\n",
    "print(len(total), total[0])\n",
    "\n",
    "todo = sorted(list(set(total).difference(set(completed))))\n",
    "print(len(todo))\n",
    "\n",
    "f = open(\"remainingModels.txt\", \"w\")\n",
    "for line in todo:\n",
    "    f.write(line + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fecb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To solve the errors\n",
    "channel=\"phi\"\n",
    "f = open(\"commands_temp.txt\", \"w\")\n",
    "\n",
    "file_path = \"errorFiles.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        jobName = line.strip().split(\"/\")[-1][:-4]\n",
    "        dfC = jobName.split(\"_\")[0].replace(\"df\", \"\")\n",
    "        dlC = jobName.split(\"_\")[1].replace(\"dl\", \"\")\n",
    "        listVars = [int(x.replace(\"v\", \"\")) for x in jobName.split(\"_\")[2:]]\n",
    "        comm = \"df{dfC}_dl{dlC}_{varNames}:root -l -q -b 'TMVA_GF_regression.C(\\\"BDTG_df{dfC}_dl{dlC}_{varNames}\\\", \\\"{channel}\\\", 0, {{{listVars}}}, {dfC}, {dlC})' && root -l -q -b 'TMVA_GF_regression.C(\\\"BDTG_df{dfC}_dl{dlC}_{varNames}\\\", \\\"{channel}\\\", 1, {{{listVars}}}, {dfC}, {dlC})' && root -l -q -b 'TMVA_GF_regression.C(\\\"BDTG_df{dfC}_dl{dlC}_{varNames}\\\", \\\"{channel}\\\", 2, {{{listVars}}}, {dfC}, {dlC})' && python computeErrors.py -m BDTG_df{dfC}_dl{dlC}_{varNames} -c {channel}\".format(dfC=dfC, dlC=dlC, channel=channel, listVars=str(listVars)[1:-1], varNames=getVarNames(listVars))\n",
    "        print(comm)\n",
    "        f.write(comm + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98fe559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the commands for the remaining models\n",
    "channel=\"phi\"\n",
    "f = open(\"commands_temp.txt\", \"w\")\n",
    "\n",
    "file_path = \"remainingModels.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        jobName = line.strip()\n",
    "        dfC = jobName.split(\"_\")[1].replace(\"df\", \"\")\n",
    "        dlC = jobName.split(\"_\")[2].replace(\"dl\", \"\")\n",
    "        listVars = [int(x.replace(\"v\", \"\")) for x in jobName.split(\"_\")[3:]]\n",
    "        comm = \"df{dfC}_dl{dlC}_{varNames}:root -l -q -b 'TMVA_GF_regression.C(\\\"BDTG_df{dfC}_dl{dlC}_{varNames}\\\", \\\"{channel}\\\", 0, {{{listVars}}}, {dfC}, {dlC})' && root -l -q -b 'TMVA_GF_regression.C(\\\"BDTG_df{dfC}_dl{dlC}_{varNames}\\\", \\\"{channel}\\\", 1, {{{listVars}}}, {dfC}, {dlC})' && root -l -q -b 'TMVA_GF_regression.C(\\\"BDTG_df{dfC}_dl{dlC}_{varNames}\\\", \\\"{channel}\\\", 2, {{{listVars}}}, {dfC}, {dlC})' && python computeErrors.py -m BDTG_df{dfC}_dl{dlC}_{varNames} -c {channel}\".format(dfC=dfC, dlC=dlC, channel=channel, listVars=str(listVars)[1:-1], varNames=getVarNames(listVars))\n",
    "        print(comm)\n",
    "        f.write(comm + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf1b940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
